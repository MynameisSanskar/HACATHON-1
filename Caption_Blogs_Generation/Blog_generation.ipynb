{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urLvnG9k1Fcv",
        "outputId": "cabc3938-6f8b-479c-b265-e780ad23827a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai\n",
            "  Downloading crewai-0.10.0-py3-none-any.whl (31 kB)\n",
            "Collecting langchain==0.1.0 (from crewai)\n",
            "  Downloading langchain-0.1.0-py3-none-any.whl (797 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.0/798.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai<0.0.3,>=0.0.2 (from crewai)\n",
            "  Downloading langchain_openai-0.0.2.post1-py3-none-any.whl (28 kB)\n",
            "Collecting openai<2.0.0,>=1.7.1 (from crewai)\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api<2.0.0,>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_api-1.22.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.22.0-py3-none-any.whl (16 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_sdk-1.22.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from crewai) (2.6.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0->crewai) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0->crewai) (2.0.25)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0->crewai) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0->crewai) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.0->crewai)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.1.0->crewai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.9 (from langchain==0.1.0->crewai)\n",
            "  Downloading langchain_community-0.0.19-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.7 (from langchain==0.1.0->crewai)\n",
            "  Downloading langchain_core-0.1.22-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.77 (from langchain==0.1.0->crewai)\n",
            "  Downloading langsmith-0.0.90-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0->crewai) (1.23.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0->crewai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0->crewai) (8.2.3)\n",
            "Collecting tiktoken<0.6.0,>=0.5.2 (from langchain-openai<0.0.3,>=0.0.2->crewai)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.7.1->crewai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.7.1->crewai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.7.1->crewai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.7.1->crewai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.7.1->crewai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.7.1->crewai) (4.9.0)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Collecting backoff<3.0.0,>=1.10.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (1.62.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.22.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.22.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.22.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_proto-1.22.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<5.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto==1.22.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (3.20.3)\n",
            "Collecting opentelemetry-semantic-conventions==0.43b0 (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_semantic_conventions-0.43b0-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai) (2.16.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0->crewai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0->crewai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0->crewai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0->crewai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0->crewai) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.7.1->crewai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.7.1->crewai) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.0->crewai)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.0->crewai)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai) (1.14.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.7.1->crewai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.7.1->crewai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.7.1->crewai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai) (3.17.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.1.0->crewai)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.77 (from langchain==0.1.0->crewai)\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain==0.1.0->crewai) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.0->crewai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.0->crewai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.0->crewai) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai<0.0.3,>=0.0.2->crewai) (2023.12.25)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.0->crewai)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: opentelemetry-semantic-conventions, opentelemetry-proto, mypy-extensions, marshmallow, jsonpointer, importlib-metadata, h11, deprecated, backoff, typing-inspect, tiktoken, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonpatch, httpcore, opentelemetry-sdk, langsmith, httpx, dataclasses-json, opentelemetry-exporter-otlp-proto-http, openai, langchain-core, langchain-openai, langchain-community, langchain, crewai\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 7.0.1\n",
            "    Uninstalling importlib-metadata-7.0.1:\n",
            "      Successfully uninstalled importlib-metadata-7.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 crewai-0.10.0 dataclasses-json-0.6.4 deprecated-1.2.14 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 importlib-metadata-6.11.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.0 langchain-community-0.0.19 langchain-core-0.1.22 langchain-openai-0.0.2.post1 langsmith-0.0.87 marshmallow-3.20.2 mypy-extensions-1.0.0 openai-1.12.0 opentelemetry-api-1.22.0 opentelemetry-exporter-otlp-proto-common-1.22.0 opentelemetry-exporter-otlp-proto-http-1.22.0 opentelemetry-proto-1.22.0 opentelemetry-sdk-1.22.0 opentelemetry-semantic-conventions-0.43b0 tiktoken-0.5.2 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install crewai\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install duckduckgo-search\n",
        "!pip install langchain_google_genai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IGjjkmf1JiV",
        "outputId": "df6c03fc-3b47-42d9-fe22-358f3eda4c20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-4.4.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Collecting curl-cffi>=0.6.0b9 (from duckduckgo-search)\n",
            "  Downloading curl_cffi-0.6.0b9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lxml>=5.1.0 (from duckduckgo-search)\n",
            "  Downloading lxml-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (1.6.0)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from curl-cffi>=0.6.0b9->duckduckgo-search) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from curl-cffi>=0.6.0b9->duckduckgo-search) (2024.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12.0->curl-cffi>=0.6.0b9->duckduckgo-search) (2.21)\n",
            "Installing collected packages: lxml, curl-cffi, duckduckgo-search\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.9.4\n",
            "    Uninstalling lxml-4.9.4:\n",
            "      Successfully uninstalled lxml-4.9.4\n",
            "Successfully installed curl-cffi-0.6.0b9 duckduckgo-search-4.4.1 lxml-5.1.0\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-0.0.8-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: google-generativeai<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.3.2)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.1.22)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain_google_genai) (0.4.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain_google_genai) (2.17.3)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain_google_genai) (2.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain_google_genai) (4.9.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain_google_genai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain_google_genai) (4.66.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai) (1.23.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_google_genai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_google_genai) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.0.88,>=0.0.87 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_google_genai) (0.0.87)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_google_genai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_google_genai) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_google_genai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_google_genai) (8.2.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain_google_genai) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain_google_genai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain_google_genai) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain_google_genai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain_google_genai) (2.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain_google_genai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain_google_genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain_google_genai) (2024.2.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai) (1.62.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai) (4.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai) (1.60.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai) (0.5.1)\n",
            "Installing collected packages: langchain_google_genai\n",
            "Successfully installed langchain_google_genai-0.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "# from tools.browser_tools import BrowserTools\n",
        "# from tools.search_tools import SearchTools\n",
        "\n",
        "# Set gemini pro as llm\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
        "                             verbose = True,\n",
        "                             temperature = 0.5,\n",
        "                             google_api_key=\"AIzaSyCInsVMrvUlSo3oSw967hbGNO4Q9S3TD7U\")\n",
        "\n",
        "\n",
        "#create searches\n",
        "tool_search = DuckDuckGoSearchRun()\n",
        "\n",
        "# Define Agents\n",
        "email_author = Agent(\n",
        "    role='Professional Email Author',\n",
        "    goal='Craft concise and engaging emails',\n",
        "    backstory='Experienced in writing impactful marketing emails.',\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm,\n",
        "    tools=[\n",
        "        tool_search\n",
        "      ]\n",
        ")\n",
        "marketing_strategist = Agent(\n",
        "    role='Marketing Strategist',\n",
        "    goal='Lead the team in creating effective cold emails',\n",
        "    backstory='A seasoned Chief Marketing Officer with a keen eye for standout marketing content.',\n",
        "    verbose=True,\n",
        "    allow_delegation=True,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "content_specialist = Agent(\n",
        "    role='Content Specialist',\n",
        "    goal='Critique and refine social content',\n",
        "    backstory='A professional copywriter with a wealth of experience in persuasive writing.',\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "lead_analyst=Agent(\n",
        "\t\t\trole=\"Lead Market Analyst\",\n",
        "\t\t\tgoal=(\"\"\"\\\n",
        "\t\t\t\tConduct amazing analysis of the products and\n",
        "\t\t\t\tcompetitors, providing in-depth insights to guide\n",
        "\t\t\t\tmarketing strategies.\"\"\"),\n",
        "\t\t\tbackstory=(\"\"\"\\\n",
        "\t\t\t\tAs the Lead Market Analyst at a premier\n",
        "\t\t\t\tdigital marketing firm, you specialize in dissecting\n",
        "\t\t\t\tonline business landscapes.\"\"\"),\n",
        "\t\t\ttools=[\n",
        "\t\t\t\t\t# BrowserTools.scrape_and_summarize_website,\n",
        "\t\t\t\t\t# SearchTools.search_internet\n",
        "     tool_search\n",
        "\t\t\t],\n",
        "\t\t\tallow_delegation=False,\n",
        "\t\t\tllm=llm,\n",
        "\t\t\tverbose=True\n",
        "\t\t)\n",
        "\n",
        "strategy_planner_agent=Agent(\n",
        "\t\t\trole=\"Chief Marketing Strategist\",\n",
        "\t\t\tgoal=(\"\"\"\\\n",
        "\t\t\t\tSynthesize amazing insights from product analysis\n",
        "\t\t\t\tto formulate incredible marketing strategies.\"\"\"),\n",
        "\t\t\tbackstory=(\"\"\"\\\n",
        "\t\t\t\tYou are the Chief Marketing Strategist at\n",
        "\t\t\t\ta leading digital marketing agency, known for crafting\n",
        "\t\t\t\tbespoke strategies that drive success.\"\"\"),\n",
        "\t\t\ttools=[\n",
        "\t\t\t\t\t# BrowserTools.scrape_and_summarize_website,\n",
        "\t\t\t\t\t# SearchTools.search_internet,\n",
        "\t\t\t\t\t# SearchTools.search_instagram\n",
        "     tool_search\n",
        "\t\t\t],\n",
        "\t\t\tllm=llm,\n",
        "\t\t\tverbose=True\n",
        "\t\t)\n",
        "strategy_planner_agent=Agent(\n",
        "\t\t\trole=\"Chief Marketing Strategist\",\n",
        "\t\t\tgoal=(\"\"\"\\\n",
        "\t\t\t\tSynthesize amazing insights from product analysis\n",
        "\t\t\t\tto formulate incredible marketing strategies.\"\"\"),\n",
        "\t\t\tbackstory=(\"\"\"\\\n",
        "\t\t\t\tYou are the Chief Marketing Strategist at\n",
        "\t\t\t\ta leading digital marketing agency, known for crafting\n",
        "\t\t\t\tbespoke strategies that drive success.\"\"\"),\n",
        "\t\t\ttools=[\n",
        "\t\t\t\t\ttool_search\n",
        "\t\t\t],\n",
        "\t\t\tllm=llm,\n",
        "\t\t\tverbose=True\n",
        "\t\t)\n",
        "# Define Task\n",
        "email_task = Task(\n",
        "    description='''1. Generate a caption for artisans to be uploaded on social media and maximise their earning through digital marketing\n",
        "    2. Evaluate the written emails for their effectiveness and engagement.\n",
        "    3. Scrutinize the emails for grammatical correctness and clarity.\n",
        "    4. Adjust the emails to align with best practices for cold outreach. Consider the feedback\n",
        "    provided to the marketing_strategist.\n",
        "    5. Revise the emails based on all feedback, creating two final versions.''',\n",
        "    agent=strategy_planner_agent  # The Marketing Strategist is in charge and can delegate\n",
        ")\n",
        "product_name = input(\"Enter the product name: \")\n",
        "product_example = input(\"Enter an example of the product (e.g., pottery): \")\n",
        "\n",
        "# Modify task description with user input\n",
        "caption_generation_task = Task(\n",
        "    description=f'''Generate a caption for the {product_name} product, for example, {product_example}, to be uploaded on social media and maximize their earnings through digital marketing. Provide up to 5 bullet points, each consisting of small sentences and simple words (up to 5 words each).''',\n",
        "    agent=content_specialist  # The Content Specialist is in charge and can delegate\n",
        ")\n",
        "# Create a Single Crew\n",
        "email_crew = Crew(\n",
        "    agents=[strategy_planner_agent,lead_analyst, content_specialist],\n",
        "    tasks=[caption_generation_task],\n",
        "    verbose=True,\n",
        "    process=Process.sequential\n",
        ")\n",
        "\n",
        "# Execution Flow\n",
        "print(\"Crew: Working on caption Task\")\n",
        "emails_output = email_crew.kickoff()"
      ],
      "metadata": {
        "id": "vQujzE641M6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "\n",
        "# Set gemini pro as llm\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
        "                             verbose=True,\n",
        "                             temperature=0.5,\n",
        "                             google_api_key=\"AIzaSyCInsVMrvUlSo3oSw967hbGNO4Q9S3TD7U\")\n",
        "\n",
        "# Create searches\n",
        "tool_search = DuckDuckGoSearchRun()\n",
        "\n",
        "# Define Agents\n",
        "blog_writer = Agent(\n",
        "    role='Blog Writer',\n",
        "    goal='Create engaging and informative blog posts',\n",
        "    backstory='Experienced in crafting compelling narratives and informative content for various audiences.',\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm,\n",
        "    tools=[tool_search]\n",
        ")\n",
        "\n",
        "editor = Agent(\n",
        "    role='Editor',\n",
        "    goal='Ensure the quality and coherence of blog content',\n",
        "    backstory='Proficient in refining and polishing written content to meet high editorial standards.',\n",
        "    verbose=True,\n",
        "    allow_delegation=True,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "seo_expert = Agent(\n",
        "    role='SEO Expert',\n",
        "    goal='Optimize blog content for search engines',\n",
        "    backstory='Skilled in implementing SEO strategies to improve online visibility and drive traffic.',\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# Define Task\n",
        "blog_writing_task = Task(\n",
        "    description='Write a blog post on a trending topic in the industry. Ensure it is well-researched, engaging, and optimized for SEO.',\n",
        "    agent=blog_writer  # The Blog Writer is in charge and can delegate\n",
        ")\n",
        "\n",
        "# Create a Crew for Blog Writing\n",
        "blog_writing_crew = Crew(\n",
        "    agents=[blog_writer, editor, seo_expert],\n",
        "    tasks=[blog_writing_task],\n",
        "    verbose=True,\n",
        "    process=Process.sequential\n",
        ")\n",
        "\n",
        "# Execution Flow\n",
        "print(\"Crew: Working on Blog Writing Task\")\n",
        "blog_output = blog_writing_crew.kickoff()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLE0v8tU1xpM",
        "outputId": "7e9965f3-88b2-498c-936d-0aa6bdb57116"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crew: Working on Blog Writing Task\n",
            "[DEBUG]: Working Agent: Blog Writer\n",
            "[INFO]: Starting Task: Write a blog post on a trending topic in the industry. Ensure it is well-researched, engaging, and optimized for SEO.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: duckduckgo_search\n",
            "Action Input: What is a trending topic in the industry?\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/utilities/duckduckgo_search.py:47: UserWarning: DDGS running in an async loop. This may cause errors. Use AsyncDDGS instead.\n",
            "  with DDGS() as ddgs:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[93m \n",
            "\n",
            "With the general global economic downturn predicted to get worse before it gets better, companies are likely to remain cautious when it comes to spending and investing in radical new ideas in 2024.... In 2023, business leaders and organizations continued to contend with major shifts affecting the workplace, including the pressure of inflation on both employer and employee budgets, the emergence... Important Retail Trends Massive Investment Trends Key Consumer Trends This is an up-to-date list of key business trends in 2024, along with those that are poised to see continued growth into 2025. We'll cover the sectors, consumer behavior changes, and tech innovations driving each trend. Top Trending Topics (2024) By Si Quan Ong Reviewed by Joshua Hardwick Updated: January 23, 2024 2 min read Below are the top trending keywords in the US from the past three months. They're the keywords with the highest average search volume increase from our database of 16.2 billion keywords. Sidenote. The Marketing Trends of 2024 [Highlights] Short-form Video Content (TikTok, Reels, YouTube Shorts, etc.) will continue to rule. Creating content reflecting the brand's values will be key to retaining your customers. Native advertising/sponsored content is still valuable. Influencer marketing is still crucial.\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "Final Answer: The current economic downturn has forced businesses to be cautious with their spending and investments. This has led to a focus on optimizing existing resources and processes, rather than investing in radical new ideas. As a result, trends in the business industry for 2024 include a focus on cost-cutting, efficiency, and sustainability. Additionally, there is a growing emphasis on digital transformation and the adoption of new technologies to improve productivity and customer experience.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "[DEBUG]: [Blog Writer] Task output: The current economic downturn has forced businesses to be cautious with their spending and investments. This has led to a focus on optimizing existing resources and processes, rather than investing in radical new ideas. As a result, trends in the business industry for 2024 include a focus on cost-cutting, efficiency, and sustainability. Additionally, there is a growing emphasis on digital transformation and the adoption of new technologies to improve productivity and customer experience.\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}